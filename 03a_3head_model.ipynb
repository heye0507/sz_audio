{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from audio_dataset import MelSpectrogramDataset,denormalize\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as torch_models\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/jiajia2011us/heart_sz'\n",
    "audio_data = root + '/audio_data'\n",
    "data = root + '/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data+'/train.csv')\n",
    "df_valid = pd.read_csv(data+'/valid_test.csv')\n",
    "df_valid = df_valid[df_valid['valid']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        #A.HorizontalFlip(p=0.5),\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        #A.Resize(height=512,width=512,p=1.0),\n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ],p=1.0)\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        #A.Resize(height=512,width=512,p=1.0),\n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ],p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MelSpectrogramDataset(df_train,audio_data,img_tfms=get_train_transform())\n",
    "valid_ds = MelSpectrogramDataset(df_valid,audio_data,img_tfms=get_valid_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 149)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds),len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
    "#https://arxiv.org/abs/1908.08681v1\n",
    "#implemented for PyTorch / FastAI by lessw2020 \n",
    "#github: https://github.com/lessw2020/mish\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)\n",
    "        return x * (torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Head(nn.Module):\n",
    "    def __init__(self,ni,nc,ps=0.25):\n",
    "        '''\n",
    "        ni : input filter size\n",
    "        nc : output class size\n",
    "        ps : dropout rate\n",
    "        '''\n",
    "        super().__init__()\n",
    "        layers = ([Mish(),ConvLayer(ni,ni,act_cls=None),AdaptiveConcatPool2d(),\n",
    "                   Flatten(), LinBnDrop(ni*2,512,p=ps,act=Mish()), \n",
    "                   LinBnDrop(512,nc,p=ps*2)])\n",
    "        self.head = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        return self.head(xb)\n",
    "    \n",
    "class Resnet_audio(nn.Module):\n",
    "    def __init__(self,arch,nc=[1,1,1],pretrained=True):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(*list(arch(pretrained=pretrained).children())[:-2])\n",
    "       \n",
    "        # change input filter size to 1\n",
    "#         nf,ni,h,w = self.body[0].weight.shape\n",
    "#         w = self.body[0].weight.sum(dim=1,keepdim=True)\n",
    "#         conv_input = conv2d(1,nf,ks=h)\n",
    "#         conv_input.weight.data = w\n",
    "#         self.body[0] = conv_input\n",
    "        \n",
    "        # multi-head output\n",
    "        # 1,1,1 regression head\n",
    "        ni = num_features_model(self.body)\n",
    "        self.head_tsh = Model_Head(ni,nc[0])\n",
    "        self.head_t3 = Model_Head(ni,nc[1])\n",
    "        self.head_t4 = Model_Head(ni,nc[2])\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.body(x)\n",
    "        return (self.head_tsh(x),self.head_t3(x),self.head_t4(x))\n",
    "    \n",
    "# replace all relu layer with Mish        \n",
    "def to_mish(model):\n",
    "    for name,child in model.named_children():\n",
    "        if isinstance(child,nn.ReLU):\n",
    "            setattr(model,name,Mish())\n",
    "        else:\n",
    "            to_mish(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Resnet_audio(torch_models.resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_multi_head(nn.Module):\n",
    "    def __init__(self,weights=[1,1,1]):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "        \n",
    "    def forward(self,preds,target):\n",
    "        outp_tsh,outp_t3,outp_t4 = preds\n",
    "        outp_tsh,outp_t3,outp_t4 = outp_tsh.float(),outp_t3.float(),outp_t4.float()\n",
    "        targ_tsh,targ_t3,targ_t4 = target[0]\n",
    "        return (\n",
    "            self.weights[0] * F.mse_loss(outp_tsh.squeeze(),targ_tsh)\n",
    "            + self.weights[1] * F.mse_loss(outp_t3.squeeze(),targ_t3)\n",
    "            + self.weights[2] * F.mse_loss(outp_t4.squeeze(),targ_t4)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not done #\n",
    "def audio_mse(inp,targ):\n",
    "    outp_tsh,outp_t3,outp_t4 = inp\n",
    "    outp_tsh,outp_t3,outp_t4 = outp_tsh.float(),outp_t3.float(),outp_t4.float()\n",
    "    targ_tsh,targ_t3,targ_t4 = targ[0]\n",
    "    return (\n",
    "        self.weights[0] * F.mse_loss(outp_tsh.squeeze(),targ_tsh)\n",
    "        + self.weights[1] * F.mse_loss(outp_t3.squeeze(),targ_t3)\n",
    "        + self.weights[2] * F.mse_loss(outp_t4.squeeze(),targ_t4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = Loss_multi_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        sampler=RandomSampler(train_ds),\n",
    "        batch_size=32,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(valid_ds),\n",
    "        pin_memory=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(train_ds, valid_ds,bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 128, 235]), 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape,len(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(175.6771, dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds,b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls,model,loss_func=loss_func,metrics=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
