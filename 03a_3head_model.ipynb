{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_dataset import MelSpectrogramDataset,denormalize\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/haohe/Desktop/Heart_shenzhen'\n",
    "audio_data = root + '/audio'\n",
    "data = root + '/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data+'/train.csv')\n",
    "df_valid = pd.read_csv(data+'/valid_test.csv')\n",
    "df_valid = df_valid[df_valid['valid']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        #A.HorizontalFlip(p=0.5),\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        #A.Resize(height=512,width=512,p=1.0),\n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ],p=1.0)\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        #A.Resize(height=512,width=512,p=1.0),\n",
    "        A.Normalize(p=1.0),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ],p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MelSpectrogramDataset(df_train,audio_data,img_tfms=get_train_transform())\n",
    "valid_ds = MelSpectrogramDataset(df_valid,audio_data,img_tfms=get_valid_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mish - \"Mish: A Self Regularized Non-Monotonic Neural Activation Function\"\n",
    "#https://arxiv.org/abs/1908.08681v1\n",
    "#implemented for PyTorch / FastAI by lessw2020 \n",
    "#github: https://github.com/lessw2020/mish\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)\n",
    "        return x * (torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Head(nn.Module):\n",
    "    def __init__(self,ni,nc,ps=0.25):\n",
    "        '''\n",
    "        ni : input filter size\n",
    "        nc : output class size\n",
    "        ps : dropout rate\n",
    "        '''\n",
    "        super().__init__()\n",
    "        layers = ([Mish(),conv2d(ni,ni),batchnorm_2d(ni),AdaptiveConcatPool2d(),Flatten()] \n",
    "                  + bn_drop_lin(ni*2,512,p=ps,actn=Mish()) \n",
    "                  + bn_drop_lin(512,nc,p=ps*2))\n",
    "        self.head = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        return self.head(xb)\n",
    "    \n",
    "class Resnet_1ch(nn.Module):\n",
    "    def __init__(self,arch,nc=[1,1,1],pretrained=True):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(*list(arch(pretrained=pretrained).children())[:-2])\n",
    "       \n",
    "        # change input filter size to 1\n",
    "        nf,ni,h,w = self.body[0].weight.shape\n",
    "        w = self.body[0].weight.sum(dim=1,keepdim=True)\n",
    "        conv_input = conv2d(1,nf,ks=h)\n",
    "        conv_input.weight.data = w\n",
    "        self.body[0] = conv_input\n",
    "        \n",
    "        # multi-head output\n",
    "        # 168,11,7 from num of unique labels\n",
    "        ni = num_features_model(self.body)\n",
    "        self.head_grapheme = Model_Head(ni,nc[0])\n",
    "        self.head_vowel = Model_Head(ni,nc[1])\n",
    "        self.head_consonant = Model_Head(ni,nc[2])\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.body(x)\n",
    "        return (self.head_grapheme(x),self.head_vowel(x),self.head_consonant(x))\n",
    "    \n",
    "# replace all relu layer with Mish        \n",
    "def to_mish(model):\n",
    "    for name,child in model.named_children():\n",
    "        if isinstance(child,nn.ReLU):\n",
    "            setattr(model,name,Mish())\n",
    "        else:\n",
    "            to_mish(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
